{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"[INFO] Running in VSCODE, installing requirements.\")\n",
    "# !pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install PyMuPDF \n",
    "# !pip install tqdm\n",
    "# !pip install sentence-transformers \n",
    "# !pip install accelerate \n",
    "# !pip install bitsandbytes \n",
    "# !pip install flash-attn --no-build-isolation \n",
    "# !pip install spacy\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CDKVF7A\\OneDrive - Deere & Co\\Personal_projects\\RAG\\venvRAG\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "3623it [00:03, 1087.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 0,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''},\n",
       " {'page_number': 1,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires !pip install PyMuPDF, see: https://github.com/pymupdf/pymupdf\n",
    "import fitz # (pymupdf, found this is better than pypdf for our use case, note: licence is AGPL-3.0, keep that in mind if you want to use any code commercially)\n",
    "from tqdm.auto import tqdm # for progress bars, requires !pip install tqdm \n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
    "\n",
    "    # Other potential text formatting functions can go here\n",
    "    return cleaned_text\n",
    "\n",
    "# Open PDF and get lines/pages\n",
    "# Note: this only focuses on text, rather than images/figures etc\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing the page number\n",
    "        (adjusted), character count, word count, sentence count, token count, and the extracted text\n",
    "        for each page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)  # open a document\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\"page_number\": page_number - 0,  # adjust page numbers since our PDF starts on page 0\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "\n",
    "pdf_path = \"harrypotter.pdf\"\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages_and_texts[:][12]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1493,\n",
       "  'page_char_count': 2276,\n",
       "  'page_word_count': 457,\n",
       "  'page_sentence_count_raw': 64,\n",
       "  'page_token_count': 569.0,\n",
       "  'text': 'Voldemort let the silence spiral horribly before continuing. “Only one power remained to me. I could possess the bodies of others. But I dared not go where other humans were plentiful, for I knew that the Aurors were still abroad and searching for me. I sometimes inhabited animals — snakes, of course, being my preference — but I was little better off inside them than as pure spirit, for their bodies were ill adapted to perform magic . . . and my possession of them shortened their lives; none of them lasted long. . . . “Then . . . four years ago . . . the means for my return seemed assured. A wizard — young, foolish, and gullible — wandered across my path in the forest I had made my home. Oh, he seemed the very chance I had been dreaming of . . . for he was a teacher at Dumbledore’s school . . . he was easy to bend to my will . . . he brought me back to this country, and after a while, I took possession of his body, to supervise him closely as he carried out my orders. But my plan failed. I did not manage to steal the Sorcerer’s Stone. I was not to be assured immortal life. I was thwarted . . . thwarted, once again, by Harry Potter. . . .” Silence once more; nothing was stirring, not even the leaves on the yew tree. The Death Eaters were quite motionless, the glittering eyes in their masks fixed upon Voldemort, and upon Harry. “The servant died when I left his body, and I was left as weak as ever I had been,” Voldemort continued. “I returned to my hiding place far away, and I will not pretend to you that I didn’t then fear that I might never regain my powers. . . . Yes, that was perhaps my darkest hour . . . I could not hope that I would be sent another wizard to possess . . . and I had given up hope, now, that any of my Death Eaters cared what had become of me. . . .” One or two of the masked wizards in the circle moved uncomfortably, but Voldemort took no notice. “And then, not even a year ago, when I had almost abandoned hope, it happened at last . . . a servant returned to me. Wormtail here, who had faked his own death to escape justice, was driven out of hiding by those he had once counted friends, and decided to return to his master. He sought me in the country where it had long been rumored I was hiding . . . helped, of course, by'},\n",
       " {'page_number': 1178,\n",
       "  'page_char_count': 1835,\n",
       "  'page_word_count': 315,\n",
       "  'page_sentence_count_raw': 29,\n",
       "  'page_token_count': 458.75,\n",
       "  'text': 'Karkaroff. He had dropped his unctuous tone and his smile now. His face wore a very ugly look indeed. “You will set up the Goblet of Fire once more, and we will continue adding names until each school has two champions. It’s only fair, Dumbledore.” “But Karkaroff, it doesn’t work like that,” said Bagman. “The Goblet of Fire’s just gone out — it won’t reignite until the start of the next tournament —” “— in which Durmstrang will most certainly not be competing!” exploded Karkaroff. “After all our meetings and negotiations and compromises, I little expected something of this nature to occur! I have half a mind to leave now!” “Empty threat, Karkaroff,” growled a voice from near the door. “You can’t leave your champion now. He’s got to compete. They’ve all got to compete. Binding magical contract, like Dumbledore said. Convenient, eh?” Moody had just entered the room. He limped toward the fire, and with every right step he took, there was a loud clunk. “Convenient?” said Karkaroff. “I’m afraid I don’t understand you, Moody.” Harry could tell he was trying to sound disdainful, as though what Moody was saying was barely worth his notice, but his hands gave him away; they had balled themselves into fists. “Don’t you?” said Moody quietly. “It’s very simple, Karkaroff. Someone put Potter’s name in that goblet knowing he’d have to compete if it came out.” “Evidently, someone ’oo wished to give ’Ogwarts two bites at ze apple!” said Madame Maxime. “I quite agree, Madame Maxime,” said Karkaroff, bowing to her. “I shall be lodging complaints with the Ministry of Magic and the International Confederation of Wizards —” “If anyone’s got reason to complain, it’s Potter,” growled Moody, “but . . . funny thing . . . I don’t hear him saying a word. . . .” “Why should ’e complain?” burst out Fleur Delacour, stamping her foot.'},\n",
       " {'page_number': 3147,\n",
       "  'page_char_count': 2023,\n",
       "  'page_word_count': 351,\n",
       "  'page_sentence_count_raw': 17,\n",
       "  'page_token_count': 505.75,\n",
       "  'text': '“Impossible,” said Lupin. Ron looked smug, and Harry felt hugely relieved. “Apart from anything else, they’d know for sure Harry was here if he still had the Trace on him, wouldn’t they? But I can’t see how they could have tracked you to Tottenham Court Road, that’s worrying, really worrying.” He looked disturbed, but as far as Harry was concerned, that question could wait. “Tell us what happened after we left, we haven’t heard a thing since Ron’s dad told us the family were safe.” “Well, Kingsley saved us,” said Lupin. “Thanks to his warning most of the wedding guests were able to Disapparate before they arrived.” “Were they Death Eaters or Ministry people?” interjected Hermione. “A mixture; but to all intents and purposes they’re the same thing now,” said Lupin. “There were about a dozen of them, but they didn’t know you were there, Harry. Arthur heard a rumor that they tried to torture your whereabouts out of Scrimgeour before they killed him; if it’s true, he didn’t give you away.” Harry looked at Ron and Hermione; their expressions reflected the mingled shock and gratitude he felt. He had never liked Scrimgeour much, but if what Lupin said was true, the man’s final act had been to try to protect Harry. “The Death Eaters searched the Burrow from top to bottom,” Lupin went on. “They found the ghoul, but didn’t want to get too close — and then they interrogated those of us who remained for hours. They were trying to get information on you, Harry, but of course nobody apart from the Order knew that you had been there. “At the same time that they were smashing up the wedding, more Death Eaters were forcing their way into every Order-connected house in the country. No deaths,” he added quickly, forestalling the question, “but they were rough. They burned down Dedalus Diggle’s house, but as you know he wasn’t there, and they used the Cruciatus Curse on Tonks’s family. Again, trying to find out where you went after you visited them. They’re all right — shaken, obviously, but otherwise okay.”'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0            0                0                1                        1   \n",
       "1            1                0                1                        1   \n",
       "2            2                0                1                        1   \n",
       "3            3                0                1                        1   \n",
       "4            4                0                1                        1   \n",
       "\n",
       "   page_token_count text  \n",
       "0               0.0       \n",
       "1               0.0       \n",
       "2               0.0       \n",
       "3               0.0       \n",
       "4               0.0       "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1811.00</td>\n",
       "      <td>1731.71</td>\n",
       "      <td>310.02</td>\n",
       "      <td>22.82</td>\n",
       "      <td>432.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1046.01</td>\n",
       "      <td>393.21</td>\n",
       "      <td>71.15</td>\n",
       "      <td>10.75</td>\n",
       "      <td>98.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>905.50</td>\n",
       "      <td>1635.50</td>\n",
       "      <td>290.50</td>\n",
       "      <td>16.00</td>\n",
       "      <td>408.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1811.00</td>\n",
       "      <td>1814.00</td>\n",
       "      <td>324.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>453.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2716.50</td>\n",
       "      <td>1965.00</td>\n",
       "      <td>351.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>491.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3622.00</td>\n",
       "      <td>2432.00</td>\n",
       "      <td>463.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>608.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      3623.00          3623.00          3623.00                  3623.00   \n",
       "mean       1811.00          1731.71           310.02                    22.82   \n",
       "std        1046.01           393.21            71.15                    10.75   \n",
       "min           0.00             0.00             1.00                     1.00   \n",
       "25%         905.50          1635.50           290.50                    16.00   \n",
       "50%        1811.00          1814.00           324.00                    21.00   \n",
       "75%        2716.50          1965.00           351.00                    27.00   \n",
       "max        3622.00          2432.00           463.00                    90.00   \n",
       "\n",
       "       page_token_count  \n",
       "count           3623.00  \n",
       "mean             432.93  \n",
       "std               98.30  \n",
       "min                0.00  \n",
       "25%              408.88  \n",
       "50%              453.50  \n",
       "75%              491.25  \n",
       "max              608.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This another sentence.]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English # see https://spacy.io/usage for install instructions\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline, see https://spacy.io/api/sentencizer/ \n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create a document instance as an example\n",
    "doc = nlp(\"This is a sentence. This another sentence.\")\n",
    "assert len(list(doc.sents)) == 2\n",
    "\n",
    "# Access the sentences of the document\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3623/3623 [00:04<00:00, 726.83it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    \n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    \n",
    "    # Count the sentences \n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1816,\n",
       "  'page_char_count': 2230,\n",
       "  'page_word_count': 375,\n",
       "  'page_sentence_count_raw': 23,\n",
       "  'page_token_count': 557.5,\n",
       "  'text': 'homework ever. It was the same, if not worse, in Transfiguration. “You cannot pass an O.W.L.,” said Professor McGonagall grimly, “without serious application, practice, and study. I see no reason why everybody in this class should not achieve an O.W.L. in Transfiguration as long as they put in the work.” Neville made a sad little disbelieving noise. “Yes, you too, Longbottom,” said Professor McGonagall. “There’s nothing wrong with your work except lack of confidence. So . . . today we are starting Vanishing Spells. These are easier than Conjuring Spells, which you would not usually attempt until N.E.W.T. level, but they are still among the most difficult magic you will be tested on in your O.W.L.” She was quite right; Harry found the Vanishing Spells horribly difficult. By the end of a double period, neither he nor Ron had managed to vanish the snails on which they were practicing, though Ron said hopefully that he thought his looked a bit paler. Hermione, on the other hand, successfully vanished her snail on the third attempt, earning her a ten-point bonus for Gryffindor from Professor McGonagall. She was the only person not given homework; everybody else was told to practice the spell overnight, ready for a fresh attempt on their snails the following afternoon. Now panicking slightly about the amount of homework they had to do, Harry and Ron spent their lunch hour in the library looking up the uses of moonstones in potion-making. Still angry about Ron’s slur on her woolly hats, Hermione did not join them. By the time they reached Care of Magical Creatures in the afternoon, Harry’s head was aching again. The day had become cool and breezy, and, as they walked down the sloping lawn toward Hagrid’s cabin on the edge of the Forbidden Forest, they felt the occasional drop of rain on their faces. Professor Grubbly-Plank stood waiting for the class some ten yards from Hagrid’s front door, a long trestle table in front of her laden with many twigs. As Harry and Ron reached her, a loud shout of laughter sounded behind them; turning, they saw Draco Malfoy striding toward them, surrounded by his usual gang of Slytherin cronies. He had clearly just said something highly amusing, because Crabbe, Goyle,',\n",
       "  'sentences': ['homework ever.',\n",
       "   'It was the same, if not worse, in Transfiguration. “',\n",
       "   'You cannot pass an O.W.L.,” said Professor McGonagall grimly, “without serious application, practice, and study.',\n",
       "   'I see no reason why everybody in this class should not achieve an O.W.L. in Transfiguration as long as they put in the work.”',\n",
       "   'Neville made a sad little disbelieving noise. “',\n",
       "   'Yes, you too, Longbottom,” said Professor McGonagall. “',\n",
       "   'There’s nothing wrong with your work except lack of confidence.',\n",
       "   'So . . .',\n",
       "   'today we are starting Vanishing Spells.',\n",
       "   'These are easier than Conjuring Spells, which you would not usually attempt until N.E.W.T. level, but they are still among the most difficult magic you will be tested on in your O.W.L.” She was quite right; Harry found the Vanishing Spells horribly difficult.',\n",
       "   'By the end of a double period, neither he nor Ron had managed to vanish the snails on which they were practicing, though Ron said hopefully that he thought his looked a bit paler.',\n",
       "   'Hermione, on the other hand, successfully vanished her snail on the third attempt, earning her a ten-point bonus for Gryffindor from Professor McGonagall.',\n",
       "   'She was the only person not given homework; everybody else was told to practice the spell overnight, ready for a fresh attempt on their snails the following afternoon.',\n",
       "   'Now panicking slightly about the amount of homework they had to do, Harry and Ron spent their lunch hour in the library looking up the uses of moonstones in potion-making.',\n",
       "   'Still angry about Ron’s slur on her woolly hats, Hermione did not join them.',\n",
       "   'By the time they reached Care of Magical Creatures in the afternoon, Harry’s head was aching again.',\n",
       "   'The day had become cool and breezy, and, as they walked down the sloping lawn toward Hagrid’s cabin on the edge of the Forbidden Forest, they felt the occasional drop of rain on their faces.',\n",
       "   'Professor Grubbly-Plank stood waiting for the class some ten yards from Hagrid’s front door, a long trestle table in front of her laden with many twigs.',\n",
       "   'As Harry and Ron reached her, a loud shout of laughter sounded behind them; turning, they saw Draco Malfoy striding toward them, surrounded by his usual gang of Slytherin cronies.',\n",
       "   'He had clearly just said something highly amusing, because Crabbe, Goyle,'],\n",
       "  'page_sentence_count_spacy': 20}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an example\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1811.00</td>\n",
       "      <td>1731.71</td>\n",
       "      <td>310.02</td>\n",
       "      <td>22.82</td>\n",
       "      <td>432.93</td>\n",
       "      <td>24.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1046.01</td>\n",
       "      <td>393.21</td>\n",
       "      <td>71.15</td>\n",
       "      <td>10.75</td>\n",
       "      <td>98.30</td>\n",
       "      <td>7.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>905.50</td>\n",
       "      <td>1635.50</td>\n",
       "      <td>290.50</td>\n",
       "      <td>16.00</td>\n",
       "      <td>408.88</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1811.00</td>\n",
       "      <td>1814.00</td>\n",
       "      <td>324.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>453.50</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2716.50</td>\n",
       "      <td>1965.00</td>\n",
       "      <td>351.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>491.25</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3622.00</td>\n",
       "      <td>2432.00</td>\n",
       "      <td>463.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>608.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      3623.00          3623.00          3623.00                  3623.00   \n",
       "mean       1811.00          1731.71           310.02                    22.82   \n",
       "std        1046.01           393.21            71.15                    10.75   \n",
       "min           0.00             0.00             1.00                     1.00   \n",
       "25%         905.50          1635.50           290.50                    16.00   \n",
       "50%        1811.00          1814.00           324.00                    21.00   \n",
       "75%        2716.50          1965.00           351.00                    27.00   \n",
       "max        3622.00          2432.00           463.00                    90.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count           3623.00                    3623.00  \n",
       "mean             432.93                      24.12  \n",
       "std               98.30                       7.58  \n",
       "min                0.00                       0.00  \n",
       "25%              408.88                      20.00  \n",
       "50%              453.50                      25.00  \n",
       "75%              491.25                      29.00  \n",
       "max              608.00                      50.00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3623/3623 [00:00<00:00, 278681.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 620,\n",
       "  'page_char_count': 1810,\n",
       "  'page_word_count': 317,\n",
       "  'page_sentence_count_raw': 18,\n",
       "  'page_token_count': 452.5,\n",
       "  'text': 'Ron lifted Scabbers out of his inside pocket and placed him next to the cage of his fellow rats, who stopped their skipping tricks and scuffled to the wire for a better look. Like nearly everything Ron owned, Scabbers the rat was second-hand (he had once belonged to Ron’s brother Percy) and a bit battered. Next to the glossy rats in the cage, he looked especially woebegone. “Hm,” said the witch, picking up Scabbers. “How old is this rat?” “Dunno,” said Ron. “Quite old. He used to belong to my brother.” “What powers does he have?” said the witch, examining Scabbers closely. “Er —” The truth was that Scabbers had never shown the faintest trace of interesting powers. The witch’s eyes moved from Scabbers’s tattered left ear to his front paw, which had a toe missing, and tutted loudly. “He’s been through the mill, this one,” she said. “He was like that when Percy gave him to me,” said Ron defensively. “An ordinary common or garden rat like this can’t be expected to live longer than three years or so,” said the witch. “Now, if you were looking for something a bit more hard-wearing, you might like one of these —” She indicated the black rats, who promptly started skipping again. Ron muttered, “Show-offs.” “Well, if you don’t want a replacement, you can try this rat tonic,” said the witch, reaching under the counter and bringing out a small red bottle. “Okay,” said Ron. “How much — OUCH!” Ron buckled as something huge and orange came soaring from the top of the highest cage, landed on his head, and then propelled itself, spitting madly, at Scabbers. “NO, CROOKSHANKS, NO!” cried the witch, but Scabbers shot from between her hands like a bar of soap, landed splay-legged on the floor, and then scampered for the door. “Scabbers!” Ron shouted, racing out of the shop after him; Harry followed.',\n",
       "  'sentences': ['Ron lifted Scabbers out of his inside pocket and placed him next to the cage of his fellow rats, who stopped their skipping tricks and scuffled to the wire for a better look.',\n",
       "   'Like nearly everything Ron owned, Scabbers the rat was second-hand (he had once belonged to Ron’s brother Percy) and a bit battered.',\n",
       "   'Next to the glossy rats in the cage, he looked especially woebegone. “',\n",
       "   'Hm,” said the witch, picking up Scabbers. “',\n",
       "   'How old is this rat?” “',\n",
       "   'Dunno,” said Ron. “',\n",
       "   'Quite old.',\n",
       "   'He used to belong to my brother.” “',\n",
       "   'What powers does he have?”',\n",
       "   'said the witch, examining Scabbers closely. “',\n",
       "   'Er —” The truth was that Scabbers had never shown the faintest trace of interesting powers.',\n",
       "   'The witch’s eyes moved from Scabbers’s tattered left ear to his front paw, which had a toe missing, and tutted loudly. “',\n",
       "   'He’s been through the mill, this one,” she said. “',\n",
       "   'He was like that when Percy gave him to me,” said Ron defensively. “',\n",
       "   'An ordinary common or garden rat like this can’t be expected to live longer than three years or so,” said the witch. “',\n",
       "   'Now, if you were looking for something a bit more hard-wearing, you might like one of these —” She indicated the black rats, who promptly started skipping again.',\n",
       "   'Ron muttered, “Show-offs.” “',\n",
       "   'Well, if you don’t want a replacement, you can try this rat tonic,” said the witch, reaching under the counter and bringing out a small red bottle. “',\n",
       "   'Okay,” said Ron. “',\n",
       "   'How much — OUCH!”',\n",
       "   'Ron buckled as something huge and orange came soaring from the top of the highest cage, landed on his head, and then propelled itself, spitting madly, at Scabbers. “',\n",
       "   'NO, CROOKSHANKS, NO!”',\n",
       "   'cried the witch, but Scabbers shot from between her hands like a bar of soap, landed splay-legged on the floor, and then scampered for the door. “',\n",
       "   'Scabbers!”',\n",
       "   'Ron shouted, racing out of the shop after him; Harry followed.'],\n",
       "  'page_sentence_count_spacy': 25,\n",
       "  'sentence_chunks': [['Ron lifted Scabbers out of his inside pocket and placed him next to the cage of his fellow rats, who stopped their skipping tricks and scuffled to the wire for a better look.',\n",
       "    'Like nearly everything Ron owned, Scabbers the rat was second-hand (he had once belonged to Ron’s brother Percy) and a bit battered.',\n",
       "    'Next to the glossy rats in the cage, he looked especially woebegone. “',\n",
       "    'Hm,” said the witch, picking up Scabbers. “',\n",
       "    'How old is this rat?” “',\n",
       "    'Dunno,” said Ron. “',\n",
       "    'Quite old.',\n",
       "    'He used to belong to my brother.” “',\n",
       "    'What powers does he have?”',\n",
       "    'said the witch, examining Scabbers closely. “'],\n",
       "   ['Er —” The truth was that Scabbers had never shown the faintest trace of interesting powers.',\n",
       "    'The witch’s eyes moved from Scabbers’s tattered left ear to his front paw, which had a toe missing, and tutted loudly. “',\n",
       "    'He’s been through the mill, this one,” she said. “',\n",
       "    'He was like that when Percy gave him to me,” said Ron defensively. “',\n",
       "    'An ordinary common or garden rat like this can’t be expected to live longer than three years or so,” said the witch. “',\n",
       "    'Now, if you were looking for something a bit more hard-wearing, you might like one of these —” She indicated the black rats, who promptly started skipping again.',\n",
       "    'Ron muttered, “Show-offs.” “',\n",
       "    'Well, if you don’t want a replacement, you can try this rat tonic,” said the witch, reaching under the counter and bringing out a small red bottle. “',\n",
       "    'Okay,” said Ron. “',\n",
       "    'How much — OUCH!”'],\n",
       "   ['Ron buckled as something huge and orange came soaring from the top of the highest cage, landed on his head, and then propelled itself, spitting madly, at Scabbers. “',\n",
       "    'NO, CROOKSHANKS, NO!”',\n",
       "    'cried the witch, but Scabbers shot from between her hands like a bar of soap, landed splay-legged on the floor, and then scampered for the door. “',\n",
       "    'Scabbers!”',\n",
       "    'Ron shouted, racing out of the shop after him; Harry followed.']],\n",
       "  'num_chunks': 3}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample an example from the group (note: many samples have only 1 chunk as they have <=10 sentences total)\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1811.00</td>\n",
       "      <td>1731.71</td>\n",
       "      <td>310.02</td>\n",
       "      <td>22.82</td>\n",
       "      <td>432.93</td>\n",
       "      <td>24.12</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1046.01</td>\n",
       "      <td>393.21</td>\n",
       "      <td>71.15</td>\n",
       "      <td>10.75</td>\n",
       "      <td>98.30</td>\n",
       "      <td>7.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>905.50</td>\n",
       "      <td>1635.50</td>\n",
       "      <td>290.50</td>\n",
       "      <td>16.00</td>\n",
       "      <td>408.88</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1811.00</td>\n",
       "      <td>1814.00</td>\n",
       "      <td>324.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>453.50</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2716.50</td>\n",
       "      <td>1965.00</td>\n",
       "      <td>351.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>491.25</td>\n",
       "      <td>29.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3622.00</td>\n",
       "      <td>2432.00</td>\n",
       "      <td>463.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>608.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      3623.00          3623.00          3623.00                  3623.00   \n",
       "mean       1811.00          1731.71           310.02                    22.82   \n",
       "std        1046.01           393.21            71.15                    10.75   \n",
       "min           0.00             0.00             1.00                     1.00   \n",
       "25%         905.50          1635.50           290.50                    16.00   \n",
       "50%        1811.00          1814.00           324.00                    21.00   \n",
       "75%        2716.50          1965.00           351.00                    27.00   \n",
       "max        3622.00          2432.00           463.00                    90.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count           3623.00                    3623.00     3623.00  \n",
       "mean             432.93                      24.12        2.87  \n",
       "std               98.30                       7.58        0.79  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              408.88                      20.00        2.00  \n",
       "50%              453.50                      25.00        3.00  \n",
       "75%              491.25                      29.00        3.00  \n",
       "max              608.00                      50.00        5.00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to get stats\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3623/3623 [00:00<00:00, 20675.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10396"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 3557,\n",
       "  'sentence_chunk': 'A frightened teenage boy is a danger to others as well as to himself. Offer him help and guidance, he ought to accept, he likes you —” “— much less since his father has lost favor. Draco blames me, he thinks I have usurped Lucius’s position.” “All the same, try. I am concerned less for myself than for accidental victims of whatever schemes might occur to the boy. Ultimately, of course, there is only one thing to be done if we are to save him from Lord',\n",
       "  'chunk_char_count': 455,\n",
       "  'chunk_word_count': 87,\n",
       "  'chunk_token_count': 113.75}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a random sample\n",
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10396.00</td>\n",
       "      <td>10396.00</td>\n",
       "      <td>10396.00</td>\n",
       "      <td>10396.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1793.17</td>\n",
       "      <td>601.16</td>\n",
       "      <td>106.35</td>\n",
       "      <td>150.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1045.34</td>\n",
       "      <td>306.58</td>\n",
       "      <td>54.11</td>\n",
       "      <td>76.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>887.00</td>\n",
       "      <td>400.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1759.50</td>\n",
       "      <td>579.00</td>\n",
       "      <td>103.00</td>\n",
       "      <td>144.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2699.00</td>\n",
       "      <td>779.00</td>\n",
       "      <td>138.00</td>\n",
       "      <td>194.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3622.00</td>\n",
       "      <td>2336.00</td>\n",
       "      <td>399.00</td>\n",
       "      <td>584.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count     10396.00          10396.00          10396.00           10396.00\n",
       "mean       1793.17            601.16            106.35             150.29\n",
       "std        1045.34            306.58             54.11              76.65\n",
       "min           5.00              1.00              1.00               0.25\n",
       "25%         887.00            400.00             71.00             100.00\n",
       "50%        1759.50            579.00            103.00             144.75\n",
       "75%        2699.00            779.00            138.00             194.75\n",
       "max        3622.00           2336.00            399.00             584.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats about our chunks\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 0\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 5,\n",
       "  'sentence_chunk': 'CONTENTS Harry Potter and the Sorcerer’s Stone Harry Potter and the Chamber of Secrets Harry Potter and the Prisoner of Azkaban Harry Potter and the Goblet of Fire Harry Potter and the Order of the Phoenix Harry Potter and the Half-Blood Prince Harry Potter and the Deathly Hallows',\n",
       "  'chunk_char_count': 281,\n",
       "  'chunk_word_count': 48,\n",
       "  'chunk_token_count': 70.25},\n",
       " {'page_number': 8,\n",
       "  'sentence_chunk': 'FOR JESSICA, WHO LOVES STORIES, FOR ANNE, WHO LOVED THEM TOO; AND FOR DI, WHO HEARD THIS ONE FIRST.',\n",
       "  'chunk_char_count': 99,\n",
       "  'chunk_word_count': 19,\n",
       "  'chunk_token_count': 24.75}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CDKVF7A\\OneDrive - Deere & Co\\Personal_projects\\RAG\\venvRAG\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentence-transformers\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=\"cuda\") # choose the device to load the model to (note: GPU will often be *much* faster than CPU)\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Print the device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10396/10396 [03:58<00:00, 43.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 51s\n",
      "Wall time: 3min 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Send the model to the GPU\n",
    "embedding_model.to(\"cuda\") # requires a GPU installed, for reference on my local machine, I'm using a NVIDIA RTX 4090\n",
    "\n",
    "# Create embeddings one by one on the GPU\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to file\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)\n",
    "# , escapechar='\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10396"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks_and_embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>CONTENTS Harry Potter and the Sorcerer’s Stone...</td>\n",
       "      <td>281</td>\n",
       "      <td>48</td>\n",
       "      <td>70.25</td>\n",
       "      <td>[ 4.88150194e-02  3.13613489e-02 -1.05375061e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>FOR JESSICA, WHO LOVES STORIES, FOR ANNE, WHO ...</td>\n",
       "      <td>99</td>\n",
       "      <td>19</td>\n",
       "      <td>24.75</td>\n",
       "      <td>[ 1.68481730e-02  1.10594528e-02 -3.13987210e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>CONTENTS ONE The Boy Who Lived TWO The Vanishi...</td>\n",
       "      <td>292</td>\n",
       "      <td>50</td>\n",
       "      <td>73.00</td>\n",
       "      <td>[ 4.38591167e-02  2.93046013e-02 -1.53083112e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>The Mirror of Erised THIRTEEN Nicolas Flamel F...</td>\n",
       "      <td>176</td>\n",
       "      <td>26</td>\n",
       "      <td>44.00</td>\n",
       "      <td>[ 6.01046197e-02  5.54131642e-02  2.76092021e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>M  CHAPTER ONE THE BOY WHO LIVED r. and Mrs. D...</td>\n",
       "      <td>1289</td>\n",
       "      <td>230</td>\n",
       "      <td>322.25</td>\n",
       "      <td>[ 1.21132750e-02  1.85709447e-02 -2.47814637e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            5  CONTENTS Harry Potter and the Sorcerer’s Stone...   \n",
       "1            8  FOR JESSICA, WHO LOVES STORIES, FOR ANNE, WHO ...   \n",
       "2            9  CONTENTS ONE The Boy Who Lived TWO The Vanishi...   \n",
       "3           10  The Mirror of Erised THIRTEEN Nicolas Flamel F...   \n",
       "4           11  M  CHAPTER ONE THE BOY WHO LIVED r. and Mrs. D...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               281                48              70.25   \n",
       "1                99                19              24.75   \n",
       "2               292                50              73.00   \n",
       "3               176                26              44.00   \n",
       "4              1289               230             322.25   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 4.88150194e-02  3.13613489e-02 -1.05375061e-...  \n",
       "1  [ 1.68481730e-02  1.10594528e-02 -3.13987210e-...  \n",
       "2  [ 4.38591167e-02  2.93046013e-02 -1.53083112e-...  \n",
       "3  [ 6.01046197e-02  5.54131642e-02  2.76092021e-...  \n",
       "4  [ 1.21132750e-02  1.85709447e-02 -2.47814637e-...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import saved file and view\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12480"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks_and_embedding_df_load['embedding'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10396, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>CONTENTS Harry Potter and the Sorcerer’s Stone...</td>\n",
       "      <td>281</td>\n",
       "      <td>48</td>\n",
       "      <td>70.25</td>\n",
       "      <td>[0.0488150194, 0.0313613489, -0.0105375061, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>FOR JESSICA, WHO LOVES STORIES, FOR ANNE, WHO ...</td>\n",
       "      <td>99</td>\n",
       "      <td>19</td>\n",
       "      <td>24.75</td>\n",
       "      <td>[0.016848173, 0.0110594528, -0.031398721, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>CONTENTS ONE The Boy Who Lived TWO The Vanishi...</td>\n",
       "      <td>292</td>\n",
       "      <td>50</td>\n",
       "      <td>73.00</td>\n",
       "      <td>[0.0438591167, 0.0293046013, -0.0153083112, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>The Mirror of Erised THIRTEEN Nicolas Flamel F...</td>\n",
       "      <td>176</td>\n",
       "      <td>26</td>\n",
       "      <td>44.00</td>\n",
       "      <td>[0.0601046197, 0.0554131642, 0.00276092021, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>M  CHAPTER ONE THE BOY WHO LIVED r. and Mrs. D...</td>\n",
       "      <td>1289</td>\n",
       "      <td>230</td>\n",
       "      <td>322.25</td>\n",
       "      <td>[0.012113275, 0.0185709447, -0.0247814637, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            5  CONTENTS Harry Potter and the Sorcerer’s Stone...   \n",
       "1            8  FOR JESSICA, WHO LOVES STORIES, FOR ANNE, WHO ...   \n",
       "2            9  CONTENTS ONE The Boy Who Lived TWO The Vanishi...   \n",
       "3           10  The Mirror of Erised THIRTEEN Nicolas Flamel F...   \n",
       "4           11  M  CHAPTER ONE THE BOY WHO LIVED r. and Mrs. D...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               281                48              70.25   \n",
       "1                99                19              24.75   \n",
       "2               292                50              73.00   \n",
       "3               176                26              44.00   \n",
       "4              1289               230             322.25   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0488150194, 0.0313613489, -0.0105375061, 0....  \n",
       "1  [0.016848173, 0.0110594528, -0.031398721, 0.00...  \n",
       "2  [0.0438591167, 0.0293046013, -0.0153083112, 0....  \n",
       "3  [0.0601046197, 0.0554131642, 0.00276092021, 0....  \n",
       "4  [0.012113275, 0.0185709447, -0.0247814637, 0.0...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.8815e-02,  3.1361e-02, -1.0538e-02,  5.4614e-02, -3.0401e-02,\n",
       "         6.9892e-02,  2.9673e-02, -3.7372e-03,  6.3727e-02, -1.1713e-02,\n",
       "         1.8052e-02,  6.1999e-02,  5.3205e-02, -6.7199e-02,  8.7563e-02,\n",
       "        -8.5908e-02,  2.5470e-02, -2.4550e-02, -8.8356e-02,  5.2592e-03,\n",
       "        -3.6130e-02,  7.0244e-02, -2.2533e-02,  1.2999e-03, -5.0225e-03,\n",
       "        -5.2841e-02, -2.7148e-02,  3.8182e-02, -3.0226e-03, -6.1530e-02,\n",
       "         1.4622e-02, -6.0864e-02,  4.5739e-03,  5.1724e-02,  2.0775e-06,\n",
       "        -2.4414e-02,  4.5324e-02, -1.4382e-03, -3.2586e-02, -2.8219e-02,\n",
       "        -1.1079e-03,  4.9997e-02,  3.1503e-02, -6.7808e-02,  2.9233e-02,\n",
       "        -2.5799e-02,  3.2630e-02,  5.9321e-02, -5.7071e-02,  1.9496e-02,\n",
       "         1.6945e-02, -1.8168e-02, -4.3047e-02, -2.0095e-02,  9.7193e-02,\n",
       "        -3.5849e-02, -1.8391e-02, -3.9925e-02,  2.7684e-02,  5.7206e-02,\n",
       "         2.1256e-03,  4.3017e-03, -3.0411e-02, -3.7727e-02,  1.1235e-02,\n",
       "         1.0682e-03, -2.7853e-03, -9.1708e-03, -5.7237e-02,  4.2683e-02,\n",
       "         3.3000e-02, -3.6216e-02, -1.6315e-02,  3.2615e-02,  1.3766e-02,\n",
       "         3.0871e-02, -2.0326e-02,  2.8314e-02,  1.2024e-02, -3.6552e-02,\n",
       "        -3.5179e-02,  2.1205e-02,  2.4974e-02,  3.2823e-03,  4.2902e-02,\n",
       "        -1.2478e-02,  1.4715e-02,  7.0226e-03, -3.6964e-02, -3.2304e-02,\n",
       "         2.6461e-02, -1.9828e-02, -9.8232e-03, -1.5202e-02,  7.9572e-02,\n",
       "        -4.3917e-03, -3.9643e-02,  4.3486e-02,  2.1549e-02, -3.9679e-03,\n",
       "        -1.7478e-02,  1.9355e-02, -3.7697e-02,  5.4821e-02,  6.1301e-02,\n",
       "        -5.5445e-02,  3.2249e-02, -2.4530e-02, -1.2164e-02,  5.1721e-02,\n",
       "        -3.2447e-03,  9.0777e-03, -8.4572e-03,  5.0092e-02, -1.1251e-02,\n",
       "        -3.0159e-02, -3.7684e-02, -7.4975e-02,  6.1509e-02,  5.4031e-02,\n",
       "         1.8124e-02,  3.4796e-02, -4.9676e-03,  2.4941e-03, -1.3853e-02,\n",
       "        -5.4151e-03, -3.2185e-02, -1.0425e-02, -2.0056e-02,  5.0332e-02,\n",
       "        -5.2272e-02, -1.6346e-02,  3.7986e-02, -2.0741e-02,  1.3955e-02,\n",
       "         8.2389e-03,  2.7353e-02,  3.7736e-02,  7.6766e-02, -7.3241e-03,\n",
       "         2.0206e-02,  5.1095e-03, -1.0838e-02,  5.4762e-02,  6.2647e-02,\n",
       "        -4.5044e-02,  6.8226e-02,  2.4179e-02, -3.3304e-03,  5.0916e-03,\n",
       "         3.1226e-02,  2.7487e-02,  2.8028e-02, -1.5674e-02,  2.9791e-02,\n",
       "         1.7290e-02, -2.2301e-02, -8.7230e-02,  1.5271e-02,  5.1534e-02,\n",
       "         4.1905e-02, -4.9602e-02,  3.1548e-02,  5.6651e-04,  6.9571e-03,\n",
       "        -6.1690e-02,  1.5358e-02, -2.1158e-02,  1.5893e-02, -7.3211e-03,\n",
       "        -1.0090e-01, -1.7591e-03, -9.5876e-03, -3.5063e-02, -1.6136e-02,\n",
       "         9.4284e-02, -1.6918e-02,  6.0259e-03, -5.0223e-02, -3.3681e-02,\n",
       "         2.1159e-02, -1.7263e-02, -1.3764e-02,  2.3107e-03,  2.2177e-02,\n",
       "         2.4553e-02, -3.6733e-02, -2.6048e-02,  5.0146e-02,  1.2792e-02,\n",
       "        -3.0813e-03,  1.7457e-02,  6.8124e-02,  2.3400e-03, -1.9706e-03,\n",
       "         2.8298e-02, -4.5279e-02, -3.6509e-02,  1.4686e-02, -2.2436e-02,\n",
       "        -7.1958e-03,  2.4860e-02,  6.1471e-02,  1.2381e-01,  3.8099e-02,\n",
       "        -2.0332e-02,  4.6263e-02, -1.4798e-03,  1.3981e-02,  5.0737e-02,\n",
       "        -3.3433e-02,  1.6390e-02,  5.9533e-02, -2.2656e-02, -6.9928e-03,\n",
       "        -2.6700e-02,  2.5863e-02, -2.2704e-02, -7.2069e-02, -1.9355e-02,\n",
       "        -1.0812e-02,  3.1342e-02, -3.3727e-02,  2.7395e-02, -7.1989e-02,\n",
       "        -9.9651e-03, -5.9269e-02, -2.8872e-02,  3.3524e-03, -7.4833e-03,\n",
       "         2.1088e-02, -3.2382e-02,  1.3775e-02,  2.4329e-02,  4.9194e-02,\n",
       "        -3.6111e-02, -2.6451e-02,  4.4187e-02,  2.1116e-02, -7.2525e-02,\n",
       "        -1.7229e-02, -8.3389e-03, -6.6830e-03,  1.8122e-02,  2.5551e-02,\n",
       "         4.3340e-02, -1.2142e-02,  3.0406e-03,  9.7599e-03,  4.3320e-02,\n",
       "         6.5256e-03, -1.7569e-02, -2.9639e-02,  8.4900e-03,  2.5769e-02,\n",
       "        -7.8611e-03, -8.6009e-02,  1.5440e-02,  7.2037e-02, -4.7589e-02,\n",
       "        -1.8586e-02, -8.1673e-03,  1.1990e-02, -1.9976e-02, -3.8162e-02,\n",
       "        -6.6488e-03,  2.7188e-02, -3.6998e-02, -3.7387e-02,  6.5541e-03,\n",
       "         3.1009e-03, -1.3271e-02,  1.1544e-02,  6.9841e-03,  2.1122e-02,\n",
       "         5.6238e-03,  2.2988e-03, -2.7769e-02, -3.6106e-02, -1.7995e-02,\n",
       "         2.0938e-02,  6.4655e-02, -2.6625e-02,  8.1655e-03,  1.0636e-02,\n",
       "         4.1319e-02, -3.1892e-02,  1.9594e-02,  3.9389e-02, -1.1461e-02,\n",
       "         2.5242e-02,  2.2262e-03, -3.6703e-04, -2.6227e-02,  2.5290e-03,\n",
       "        -2.2326e-02, -1.0245e-01, -4.8935e-02, -3.2802e-02, -2.3606e-03,\n",
       "         5.6140e-03, -6.3141e-02, -2.3114e-02,  2.3446e-03, -8.4429e-04,\n",
       "        -2.2652e-02,  1.9400e-02,  1.2820e-02,  1.7622e-02, -4.4590e-03,\n",
       "        -1.3990e-03, -2.4325e-03, -4.5819e-02, -1.7733e-02,  4.5678e-03,\n",
       "        -6.0008e-02, -4.7232e-02, -5.8288e-02, -1.2311e-02, -1.0981e-02,\n",
       "        -2.9884e-02,  4.9617e-03, -5.8526e-04, -2.4888e-04, -1.9243e-03,\n",
       "        -1.0399e-01,  5.1967e-02, -9.8901e-03, -4.5757e-03,  1.7960e-03,\n",
       "         2.8398e-02, -5.7004e-03, -1.5957e-02, -4.5816e-03,  1.0073e-02,\n",
       "         5.8078e-02, -3.0394e-03, -4.9918e-02, -1.9427e-02, -2.4077e-02,\n",
       "         5.1535e-03,  3.9223e-02, -8.9053e-03, -3.0587e-02, -7.7691e-03,\n",
       "        -1.0604e-01, -1.3899e-02, -3.6041e-02, -6.0439e-03, -8.2536e-03,\n",
       "        -3.8634e-02, -4.5560e-03,  3.1522e-02, -3.8202e-02,  2.7153e-02,\n",
       "        -5.1977e-02, -5.4054e-03,  6.0554e-02, -2.8507e-02, -3.9556e-02,\n",
       "         1.3134e-02,  1.4669e-02, -3.8263e-03,  1.4189e-02,  5.0905e-02,\n",
       "        -2.4290e-02,  2.2758e-02,  6.8697e-03, -4.2264e-02, -6.2357e-03,\n",
       "        -4.4553e-02, -4.4512e-02,  2.4633e-02,  1.6986e-02,  1.9605e-02,\n",
       "         1.1030e-02, -5.5956e-03,  2.8565e-02, -5.2090e-02, -2.4654e-02,\n",
       "        -2.5437e-02, -9.6231e-02,  5.4123e-02, -1.3865e-02, -5.1536e-04,\n",
       "         4.8038e-02,  5.7847e-02, -4.5061e-03, -2.3656e-02,  4.8712e-02,\n",
       "         4.1918e-02,  1.1583e-03,  1.7610e-05,  8.2028e-02, -3.1970e-02,\n",
       "         2.2279e-02, -2.5831e-02, -8.5371e-03, -4.7799e-02, -3.3880e-02,\n",
       "        -1.6111e-02,  2.6323e-02,  6.1466e-02, -1.2203e-02,  6.5973e-02,\n",
       "        -8.8408e-02,  7.0065e-03,  1.3482e-02, -1.6700e-02,  1.6078e-02,\n",
       "         1.6810e-02, -3.6397e-02, -1.8927e-02,  1.8797e-02, -8.2296e-03,\n",
       "         3.3415e-02,  4.7397e-02, -1.0587e-02,  3.6823e-03,  5.5524e-02,\n",
       "        -3.9442e-02,  5.3856e-02, -4.3424e-02,  3.1215e-03, -3.3977e-02,\n",
       "        -5.5199e-02,  6.8802e-02, -2.7789e-02,  6.9519e-03, -4.4756e-02,\n",
       "         2.3236e-02, -2.5179e-02, -1.0721e-02,  4.1220e-02, -6.6662e-02,\n",
       "        -2.5903e-04,  1.3115e-02, -1.0789e-03,  4.0389e-02, -4.0723e-02,\n",
       "        -1.3801e-02, -4.8393e-04,  4.4608e-02,  6.8630e-02, -1.1961e-02,\n",
       "        -1.1808e-02, -1.0663e-02,  6.7180e-02, -3.3693e-02,  4.4907e-03,\n",
       "        -3.2865e-02,  4.1287e-03, -1.1312e-02, -5.9426e-02, -4.1770e-02,\n",
       "         1.6775e-02,  5.4315e-02, -4.9548e-02,  1.8320e-02, -5.3406e-03,\n",
       "         5.8091e-02,  8.5721e-03,  5.7013e-03,  1.5697e-02, -6.2730e-02,\n",
       "         3.1381e-03, -6.8445e-02, -2.9607e-02,  1.8607e-02, -4.2746e-02,\n",
       "         4.1386e-02, -2.2400e-02, -3.2573e-02, -1.1574e-02,  8.7049e-03,\n",
       "        -5.2316e-02, -5.7032e-02, -4.7511e-02, -8.0161e-02,  1.6690e-02,\n",
       "        -5.9380e-03,  2.4677e-02, -1.3301e-02,  2.1996e-02,  2.9473e-02,\n",
       "         3.6014e-02, -9.7055e-03, -5.5394e-02,  3.2052e-02, -1.8415e-02,\n",
       "         4.7462e-02, -7.0894e-02, -2.3141e-02,  5.8432e-04,  6.1404e-02,\n",
       "         6.3285e-02, -5.9636e-02, -4.0519e-02,  7.7364e-02, -4.6324e-02,\n",
       "        -8.1683e-03,  5.5197e-02, -2.0297e-02,  4.7925e-02, -3.1007e-02,\n",
       "         6.5986e-02,  1.7675e-02, -1.3910e-03,  2.9915e-02,  4.7407e-02,\n",
       "        -4.3030e-02, -3.2836e-02, -2.1452e-02, -1.3696e-03,  2.2494e-02,\n",
       "         2.2096e-02, -2.8146e-02, -4.7153e-02,  2.8885e-02,  1.6783e-02,\n",
       "        -4.2976e-02, -3.4471e-04,  2.5417e-02, -2.0875e-03,  3.1024e-02,\n",
       "        -6.4304e-03, -1.5917e-03, -7.3169e-03,  1.7358e-02, -2.5662e-02,\n",
       "         1.9867e-02, -1.0345e-03,  1.0951e-01,  5.0321e-03, -2.8499e-02,\n",
       "         3.3387e-02, -6.7282e-02,  8.5052e-02,  6.6899e-02,  2.1409e-02,\n",
       "         1.5144e-02, -1.4528e-02,  1.1425e-02, -1.0886e-02, -4.3198e-03,\n",
       "         5.9717e-03,  5.8061e-03,  3.5178e-02,  1.1188e-02,  1.4145e-02,\n",
       "         3.3937e-02, -3.3391e-02,  1.3410e-02, -6.9139e-02, -1.6968e-02,\n",
       "        -5.8538e-33,  1.7434e-02, -2.9411e-02, -1.6504e-03,  5.7819e-02,\n",
       "        -5.2580e-02, -9.5529e-02,  1.3753e-02, -6.8962e-03, -4.4791e-02,\n",
       "         1.5067e-02, -9.0008e-03,  1.7801e-02,  3.4175e-03,  2.2136e-02,\n",
       "         2.9205e-02,  1.7044e-03,  3.1370e-02,  2.2849e-02, -1.6187e-02,\n",
       "         1.5429e-02,  5.9321e-02,  2.0431e-02,  4.5392e-02, -5.0844e-02,\n",
       "        -2.2131e-02, -8.0718e-02, -2.7800e-02, -4.5724e-02,  3.1052e-02,\n",
       "         1.0718e-02, -7.4868e-02, -2.7800e-02, -1.3174e-02, -9.4488e-03,\n",
       "         3.9578e-02, -1.1565e-02, -1.1081e-02, -1.2690e-02,  3.4366e-02,\n",
       "        -1.9475e-02,  4.4384e-02, -5.8265e-02, -4.5588e-02,  1.2877e-02,\n",
       "         7.7975e-03, -6.9584e-02,  2.6162e-02,  1.1076e-02, -8.2066e-03,\n",
       "         1.2866e-03, -3.2230e-02, -1.3836e-02, -3.5024e-02, -1.5889e-02,\n",
       "         2.7994e-02,  3.0522e-02, -2.1447e-03, -2.2162e-02, -3.5434e-02,\n",
       "         5.3299e-02, -3.1925e-02,  2.4955e-02, -3.5827e-02, -4.5127e-02,\n",
       "        -1.6712e-02,  1.8881e-02,  1.9056e-02,  2.1905e-02, -3.0439e-02,\n",
       "         9.0427e-02,  6.6219e-03,  2.0230e-02, -5.4780e-03, -3.1767e-03,\n",
       "        -3.1774e-02,  3.4175e-02, -9.0474e-03, -8.6378e-03,  4.9303e-02,\n",
       "         1.6088e-02,  3.4484e-02, -2.2351e-02,  4.5160e-03, -3.5723e-02,\n",
       "         3.3198e-02,  1.1053e-01,  1.4628e-02,  4.1692e-03, -1.1214e-02,\n",
       "        -3.3367e-02, -1.9149e-02, -6.3663e-02, -7.1379e-03, -2.5140e-03,\n",
       "        -1.1191e-01,  4.9618e-02,  2.9901e-02,  5.4416e-03, -1.6701e-03,\n",
       "         1.9509e-02,  3.3618e-02,  1.2589e-02,  2.5584e-03, -4.4896e-04,\n",
       "         2.3713e-02, -1.8729e-04, -4.4721e-02, -3.9865e-03, -2.2774e-02,\n",
       "        -4.1355e-03,  3.6176e-02,  3.9612e-03, -6.8169e-02,  3.5453e-02,\n",
       "        -5.5183e-03, -2.1246e-03,  6.0136e-03, -3.9541e-02, -5.7965e-02,\n",
       "        -3.8058e-03,  3.6759e-02,  8.8486e-03,  6.2292e-03, -1.1527e-02,\n",
       "         2.2594e-02,  2.7295e-02,  2.1615e-03, -1.4257e-02,  4.1827e-02,\n",
       "        -4.5795e-02, -4.1998e-02,  3.9632e-02,  2.7572e-07,  9.4172e-05,\n",
       "        -1.7378e-02,  3.2815e-02,  3.2799e-02, -9.6432e-04, -2.8310e-02,\n",
       "         1.4277e-02,  1.4026e-02, -2.8035e-02,  1.3098e-02,  1.4864e-02,\n",
       "        -8.3829e-03,  4.7431e-02,  1.0954e-02, -2.2642e-02, -3.7771e-03,\n",
       "        -2.6792e-02, -1.3744e-02,  9.5121e-03, -5.0914e-02, -4.0891e-03,\n",
       "         1.4592e-02,  3.1133e-02,  3.2179e-02, -2.8366e-02,  5.7542e-02,\n",
       "        -1.1994e-02, -2.5415e-02, -3.6072e-02, -5.5821e-03,  3.3987e-02,\n",
       "         4.7885e-02, -1.3300e-02, -4.4080e-02,  1.7841e-02, -1.1787e-02,\n",
       "        -1.0052e-02, -1.1131e-01, -1.0448e-02,  1.2377e-02, -5.3121e-02,\n",
       "         8.5147e-03,  1.5273e-03, -4.1732e-02,  2.1449e-02,  1.2474e-01,\n",
       "         1.4169e-02,  4.7541e-02, -1.3404e-02,  1.7542e-02,  3.9827e-02,\n",
       "        -2.7028e-02, -2.4427e-02,  5.3526e-02,  1.5832e-02,  3.1203e-02,\n",
       "         2.3472e-02, -1.4036e-02,  5.3644e-02,  2.2111e-02, -1.9645e-02,\n",
       "        -1.0873e-02,  5.4816e-03,  9.0776e-03, -1.4618e-02,  5.5397e-03,\n",
       "        -1.7678e-02,  1.9884e-34,  3.6501e-03, -7.9356e-02, -1.3600e-02,\n",
       "        -2.8791e-03,  1.2561e-02, -4.4119e-02,  5.5363e-02,  2.8320e-02,\n",
       "         2.1072e-02, -1.5425e-02, -1.8068e-03], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CDKVF7A\\OneDrive - Deere & Co\\Personal_projects\\RAG\\venvRAG\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=\"cuda\") # choose the device to load the model to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Mrs. Figg\n",
      "Time take to get scores on 10396 embeddings: 0.00212 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.5111, 0.4965, 0.4642, 0.4500, 0.4498], device='cuda:0'),\n",
       "indices=tensor([5041, 5040, 4721, 5046, 5048], device='cuda:0'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define the query\n",
    "# Note: This could be anything. But since we're working with a nutrition textbook, we'll stick with nutrition-based queries.\n",
    "query = \"Mrs. Figg\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 2. Embed the query to the same numerical space as the text examples \n",
    "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# 3. Get similarity scores with the dot product (we'll time this for fun)\n",
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "# 4. Get the top-k results (we'll keep this to 5)\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print wrapped text \n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'Mrs. Figg'\n",
      "\n",
      "Results:\n",
      "Score: 0.5111\n",
      "Text:\n",
      "Full name?”said Fudge loudly, when Mrs. Figg had perched herself nervously on\n",
      "the very edge of her seat. “Arabella Doreen Figg,” said Mrs. Figg in her quavery\n",
      "voice. “And who exactly are you?”said Fudge, in a bored and lofty voice. “I’m a\n",
      "resident of Little Whinging, close to where Harry Potter lives,” said Mrs. Figg.\n",
      "“We have no record of any witch or wizard living in Little Whinging other than\n",
      "Harry Potter,” said Madam Bones at once. “That situation has always been closely\n",
      "monitored, given . . .given past events.” “I’m a Squib,” said Mrs. Figg. “\n",
      "Page number: 1705\n",
      "\n",
      "\n",
      "Score: 0.4965\n",
      "Text:\n",
      "“Oh, very well, very well,” snapped Fudge. “Where is this person?” “I brought\n",
      "her with me,” said Dumbledore. “She’s just outside the door. Should I — ?” “No —\n",
      "Weasley, you go,” Fudge barked at Percy, who got up at once, hurried down the\n",
      "stone steps from the judge’s balcony, and hastened past Dumbledore and Harry\n",
      "without glancing at them. A moment later, Percy returned, followed by Mrs. Figg.\n",
      "She looked scared and more batty than ever. Harry wished she had thought to\n",
      "change out of her carpet slippers. Dumbledore stood up and gave Mrs. Figg his\n",
      "chair, conjuring a second one for himself. “\n",
      "Page number: 1705\n",
      "\n",
      "\n",
      "Score: 0.4642\n",
      "Text:\n",
      "Good Lord, boy, they told me you were intelligent. . . . Right . . .get inside\n",
      "and stay there,” she said as they reached number four. “I expect someone will be\n",
      "in touch with you soon enough.” “What are you going to do?”asked Harry quickly.\n",
      "“I’m going straight home,” said Mrs. Figg, staring around the dark street and\n",
      "shuddering. “I’ll need to wait for more instructions. Just stay in the house.\n",
      "Good night.” “\n",
      "Page number: 1591\n",
      "\n",
      "\n",
      "Score: 0.4500\n",
      "Text:\n",
      "Yes,” said Mrs. Figg. “I felt them. Everything went cold, and this was a very\n",
      "warm summer’s night, mark you. And I felt . . .as though all happiness had gone\n",
      "from the world . . .and I remembered . . .dreadful things . . .”Her voice shook\n",
      "and died.\n",
      "Page number: 1706\n",
      "\n",
      "\n",
      "Score: 0.4498\n",
      "Text:\n",
      "And that . . .that was what happened,” Mrs. Figg finished, somewhat lamely.\n",
      "Madam Bones looked down at Mrs. Figg in silence; Fudge was not looking at her at\n",
      "all, but fidgeting with his papers. Finally he raised his eyes and said, rather\n",
      "aggressively, “That’s what you saw, is it?” “That was what happened,” Mrs. Figg\n",
      "repeated. “Very well,” said Fudge. “You may go.”Mrs. Figg cast a frightened look\n",
      "from Fudge to Dumbledore, then got up and shuffled off toward the door again.\n",
      "Harry heard it thud shut behind her. “Not a very convincing witness,” said Fudge\n",
      "loftily. “\n",
      "Page number: 1707\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Results:\")\n",
    "# Loop through zipped together scores and indicies from torch.topk\n",
    "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "    print(\"Text:\")\n",
    "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
    "    # Print the page number too so we can reference the textbook further (and check the results)\n",
    "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def dot_product(vector1, vector2):\n",
    "    return torch.dot(vector1, vector2)\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = torch.dot(vector1, vector2)\n",
    "\n",
    "    # Get Euclidean/L2 norm of each vector (removes the magnitude, keeps direction)\n",
    "    norm_vector1 = torch.sqrt(torch.sum(vector1**2))\n",
    "    norm_vector2 = torch.sqrt(torch.sum(vector2**2))\n",
    "\n",
    "    return dot_product / (norm_vector1 * norm_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=10,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, \n",
    "                                   convert_to_tensor=True) \n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores, \n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
    "                                 n_resources_to_return: int=10):\n",
    "    \"\"\"\n",
    "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
    "\n",
    "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
    "    \"\"\"\n",
    "    \n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    # Loop through zipped together scores and indicies\n",
    "    for score, index in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
    "        # Print the page number too so we can reference the textbook further and check the results\n",
    "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 10396 embeddings: 0.00008 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.4826, 0.4691, 0.4648, 0.4644, 0.4465], device='cuda:0'),\n",
       " tensor([4655, 9121, 6704, 7087, 3597], device='cuda:0'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Ministry of Magic\"\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 10396 embeddings: 0.00007 seconds.\n",
      "Query: Ministry of Magic\n",
      "\n",
      "Results:\n",
      "Score: 0.4826\n",
      "CONTENTS   ONE Dudley Demented  TWO A Peck of Owls  THREE The Advance Guard\n",
      "FOUR Number Twelve, Grimmauld Place  FIVE The Order of the Phoenix  SIX The\n",
      "Noble and Most Ancient House of Black  SEVEN The Ministry of Magic\n",
      "Page number: 1564\n",
      "\n",
      "\n",
      "Score: 0.4691\n",
      "standing in water, his shoes, feet, and robes remained quite dry. He reached up,\n",
      "pulled the chain, and next moment had zoomed down a short chute, emerging out of\n",
      "a fireplace into the Ministry of Magic. He got up clumsily; there was a lot more\n",
      "of his body than he was accustomed to. The great Atrium seemed darker than Harry\n",
      "remembered it. Previously a golden fountain had filled the center of the hall,\n",
      "casting shimmering spots of light over the polished wooden floor and walls. Now\n",
      "a gigantic statue of black stone dominated the scene. It was rather frightening,\n",
      "this vast sculpture of a witch and a wizard sitting on ornately carved thrones,\n",
      "looking down at the Ministry workers toppling out of fireplaces below them.\n",
      "Engraved in foot-high letters at the base of the statue were the words MAGIC IS\n",
      "MIGHT. Harry received a heavy blow on the back of the legs: Another wizard had\n",
      "just flown out of the fireplace behind him. “Out of the way, can’t y — oh,\n",
      "sorry, Runcorn!”\n",
      "Page number: 3178\n",
      "\n",
      "\n",
      "Score: 0.4648\n",
      "As it whirred back into place the cool female voice sounded inside the box,\n",
      "“Welcome to the Ministry of Magic. Please state your name and business.” “Harry\n",
      "Potter, Ron Weasley, Hermione Granger,” Harry said very quickly,\n",
      "Page number: 2305\n",
      "\n",
      "\n",
      "Score: 0.4644\n",
      "Nearby, on the floor, lay a purple leaflet emblazoned with the words: ——— ISSUED\n",
      "ON BEHALF OF ——— The Ministry of Magic  PROTECTING YOUR HOME AND FAMILY AGAINST\n",
      "DARK FORCES The Wizarding community is currently under threat from an\n",
      "organization calling itself the Death Eaters. Observing the following simple\n",
      "security\n",
      "Page number: 2448\n",
      "\n",
      "\n",
      "Score: 0.4465\n",
      "They showed themselves at the Quidditch World Cup, didn’t they?Someone set off\n",
      "the Dark Mark . . .and then — did you hear about that Ministry of Magic witch\n",
      "who’s gone missing?” “Bertha Jorkins?”said Harry.\n",
      "Page number: 1225\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the texts of the top scores\n",
    "print_top_results_and_scores(query=query,\n",
    "                             embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 4 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using attention implementation: sdpa\n",
      "[INFO] Using model_id: google/gemma-2b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available \n",
    "from transformers import BitsAndBytesConfig\n",
    "# Suppress symlink warning by setting environment variable\n",
    "import os\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "\n",
    "use_quantization_config = True\n",
    "model_id = \"google/gemma-2b-it\"\n",
    "# 1. Create quantization config for smaller model loading (optional)\n",
    "# Requires !pip install bitsandbytes accelerate, see: https://github.com/TimDettmers/bitsandbytes, https://huggingface.co/docs/accelerate/\n",
    "# For models that require 4-bit quantization (use this if you have low GPU memory available)\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type=\"nf4\",\n",
    "                                         llm_int8_enable_fp32_cpu_offload =True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "# Bonus: Setup Flash Attention 2 for faster inference, default to \"sdpa\" or \"scaled dot product attention\" if it's not available\n",
    "# Flash Attention 2 requires NVIDIA GPU compute capability of 8.0 or above, see: https://developer.nvidia.com/cuda-gpus\n",
    "# Requires !pip install flash-attn, see: https://github.com/Dao-AILab/flash-attention \n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "  attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "  attn_implementation = \"sdpa\"\n",
    "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
    "\n",
    "# 2. Pick a model we'd like to use (this will depend on how much GPU memory you have available)\n",
    "#model_id = \"google/gemma-7b-it\"\n",
    "model_id = model_id # (we already set this above)\n",
    "print(f\"[INFO] Using model_id: {model_id}\")\n",
    "\n",
    "# 3. Instantiate tokenizer (tokenizer turns text into numbers ready for the model) \n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "\n",
    "# 4. Instantiate the model\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id, \n",
    "                                                #  torch_dtype=torch.float16, # datatype to use, we want float16\n",
    "                                                 device_map={\"\":0},\n",
    "                                                 low_cpu_mem_usage = True,\n",
    "                                                 trust_remote_code=True,\n",
    "                                                #  load_in_8bit_fp32_cpu_offload=True,\n",
    "                                                 quantization_config=quantization_config if use_quantization_config else None,\n",
    "                                                #  low_cpu_mem_usage=False, # use full memory \n",
    "                                                 attn_implementation=attn_implementation) # which attention version to use\n",
    "\n",
    "if not use_quantization_config: # quantization takes care of device setting automatically, so if it's not used, send model to GPU \n",
    "    llm_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1515268096"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "get_model_num_params(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mem_bytes': 2039641088, 'model_mem_mb': 1945.15, 'model_mem_gb': 1.9}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_mem_size(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Get how much memory a PyTorch model takes up.\n",
    "\n",
    "    See: https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822\n",
    "    \"\"\"\n",
    "    # Get model parameters and buffer sizes\n",
    "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
    "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "\n",
    "    # Calculate various model sizes\n",
    "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
    "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
    "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
    "\n",
    "    return {\"model_mem_bytes\": model_mem_bytes,\n",
    "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
    "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
    "\n",
    "get_model_mem_size(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "how does dumbledore die?\n",
      "\n",
      "Prompt (formatted):\n",
      "<bos><start_of_turn>user\n",
      "how does dumbledore die?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"how does dumbledore die?\"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "# Create prompt template for instruction-tuned model\n",
    "dialogue_template = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": input_text}\n",
    "]\n",
    "\n",
    "# Apply the chat template\n",
    "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                       tokenize=False, # keep as raw text (not tokenized)\n",
    "                                       add_generation_prompt=True)\n",
    "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (tokenized):\n",
      "{'input_ids': tensor([[     2,      2,    106,   1645,    108,   1139,   1721,    499, 129375,\n",
      "           1303, 235336,    107,    108,    106,   2516,    108]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CDKVF7A\\OneDrive - Deere & Co\\Personal_projects\\RAG\\venvRAG\\lib\\site-packages\\transformers\\generation\\utils.py:1885: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\CDKVF7A\\OneDrive - Deere & Co\\Personal_projects\\RAG\\venvRAG\\lib\\site-packages\\transformers\\models\\gemma\\modeling_gemma.py:540: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (tokens):\n",
      "tensor([     2,      2,    106,   1645,    108,   1139,   1721,    499, 129375,\n",
      "          1303, 235336,    107,    108,    106,   2516,    108,   3493,    603,\n",
      "           793,   5820,    689,   2113,    577,   2676,    573,   5035,    674,\n",
      "        156202,   4734,    575,    573,  14140,  30961,   4100, 235265,      1])\n",
      "\n",
      "CPU times: total: 5.69 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
    "# llm_model.to(\"cuda\")\n",
    "# Generate outputs passed on the tokenized input\n",
    "# See generate docs: https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig \n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
    "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "<bos><bos><start_of_turn>user\n",
      "how does dumbledore die?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "There is no evidence or information to support the claim that Dumbledore dies in the Harry Potter series.<eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "who is the author of harry potter series?\n",
      "\n",
      "Prompt (formatted):\n",
      "<bos><start_of_turn>user\n",
      "who is the author of harry potter series?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"who is the author of harry potter series?\"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "# Create prompt template for instruction-tuned model\n",
    "dialogue_template = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": input_text}\n",
    "]\n",
    "\n",
    "# Apply the chat template\n",
    "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                       tokenize=False, # keep as raw text (not tokenized)\n",
    "                                       add_generation_prompt=True)\n",
    "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (tokenized):\n",
      "{'input_ids': tensor([[     2,      2,    106,   1645,    108,  10569,    603,    573,   3426,\n",
      "            576,  46702,  43724,   4100, 235336,    107,    108,    106,   2516,\n",
      "            108]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "\n",
      "Model output (tokens):\n",
      "tensor([     2,      2,    106,   1645,    108,  10569,    603,    573,   3426,\n",
      "           576,  46702,  43724,   4100, 235336,    107,    108,    106,   2516,\n",
      "           108,    651,   3426,    576,    573,  14140,  30961,   4100,    603,\n",
      "           713, 235265,    747, 235265, 150250, 235265,   2475,    729,   7565,\n",
      "           575, 235248, 235274, 235315, 235318, 235308,    575, 170171, 235269,\n",
      "          6879, 235265,   2475,    603,    476,   7149,   3426,    578, 200524,\n",
      "        235265,   2475,    919,   5952,   6861,  40354,    578,   8469,   5678,\n",
      "          3069, 235303, 235256,   6142,   1105,    573,   1913,    576,    476,\n",
      "          3486,  50619,   8602,  14140,  30961, 235265,    714,   4100,    919,\n",
      "          1125,    476,   5228,  27171, 235269,    675,   1163, 235248, 235308,\n",
      "        235276, 235276,   4416,  17058,   7596,  20455, 235265,      1])\n",
      "\n",
      "CPU times: total: 19.8 s\n",
      "Wall time: 4.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
    "# llm_model.to(\"cuda\")\n",
    "# Generate outputs passed on the tokenized input\n",
    "# See generate docs: https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig \n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
    "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "<bos><bos><start_of_turn>user\n",
      "who is the author of harry potter series?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "The author of the Harry Potter series is J. K. Rowling. She was born in 1965 in Gloucestershire, England. She is a British author and philanthropist. She has written seven novels and eight related children's books about the life of a young wizard named Harry Potter. The series has been a global phenomenon, with over 500 million copies sold worldwide.<eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: who is the author of harry potter series?\n",
      "\n",
      "Output text:\n",
      "The author of the Harry Potter series is J. K. Rowling. She was born in 1965 in Gloucestershire, England. She is a British author and philanthropist. She has written seven novels and eight related children's books about the life of a young wizard named Harry Potter. The series has been a global phenomenon, with over 500 million copies sold worldwide.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input text: {input_text}\\n\")\n",
    "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harry potter questions generated with Gemini\n",
    "# gemini_questions = [\n",
    "# \"Who are the three Deathly Hallows and what are their powers?\",\n",
    "# \"Describe the history and significance of the Philosopher's Stone.\",\n",
    "# \"Compare and contrast the characters of Harry Potter and Draco Malfoy.\",\n",
    "# \"Explain the concept of a Patronus and how it is created.\",\n",
    "# \"What is the significance of the number seven in the Harry Potter series?\"\n",
    "# ]\n",
    "\n",
    "# Manually created question list\n",
    "manual_questions = [\n",
    "    \"Explain chapter one : THE BOY WHO LIVED in few words\",\n",
    "    # \"How does Dumbledore die in the novel?\",\n",
    "    # \"Is professor Snape lover of harry potter's mother?\",\n",
    "    # \"Which train station do people usually go to in london to get a train to hogwarts?\",\n",
    "    # \"What are the names of twin brothers who are friends of harry potter?\"\n",
    "]\n",
    "\n",
    "query_list = manual_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Explain chapter one : THE BOY WHO LIVED in few words\n",
      "[INFO] Time taken to get scores on 10396 embeddings: 0.00008 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.6003, 0.5518, 0.5477, 0.5393, 0.5393, 0.5348, 0.5327, 0.5324, 0.5287,\n",
       "         0.5284], device='cuda:0'),\n",
       " tensor([ 9359,   195,     4,  2787,  1546, 10235,  9360,  2790,  7481, 10269],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "query = random.choice(query_list)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, \n",
    "                     context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    # Create a base prompt with examples to help the model\n",
    "    # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
    "    # We could also write this in a txt file and import it in if we wanted.\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory and comprehensive as possible, drawing on the provided context.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\n",
    "\\nExample 1:\n",
    "Query: What is the significance of the Mirror of Erised?\n",
    "Answer: The Mirror of Erised is a magical artifact that shows the deepest, most desperate desire of a person's heart. It does not produce real objects, but rather a reflection of the viewer's most profound longing. For Harry Potter, this was seeing his parents alive and well. The mirror's name is Erised backwards, meaning \"I see red,\" indicating that it reveals desires, often connected to love and loss.\n",
    "\n",
    "\\nExample 2:\n",
    "Query: How does a Patronus charm work?\n",
    "Answer: A Patronus charm creates a positive, powerful force in the form of an animal to repel Dementors. These creatures feed on human happiness, causing feelings of despair and hopelessness. By conjuring a Patronus, a wizard or witch can shield themselves from a Dementor's influence. The form of the Patronus often reflects the individual's personality or experiences.\n",
    "\n",
    "\\nExample 3:\n",
    "Query: What are the Hogwarts Houses and their characteristics?\n",
    "Answer: Hogwarts School of Witchcraft and Wizardry is divided into four houses: Gryffindor, Hufflepuff, Ravenclaw, and Slytherin. Gryffindor values courage, chivalry, and determination. Hufflepuff emphasizes hard work, loyalty, and fair play. Ravenclaw prizes intelligence, wit, and a love of learning. Slytherin characteristics include ambition, cunning, and resourcefulness.\n",
    "\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query   \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Explain chapter one : THE BOY WHO LIVED in few words\n",
      "[INFO] Time taken to get scores on 10396 embeddings: 0.00006 seconds.\n",
      "<bos><start_of_turn>user\n",
      "Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory and comprehensive as possible, drawing on the provided context.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "\n",
      "Example 1:\n",
      "Query: What is the significance of the Mirror of Erised?\n",
      "Answer: The Mirror of Erised is a magical artifact that shows the deepest, most desperate desire of a person's heart. It does not produce real objects, but rather a reflection of the viewer's most profound longing. For Harry Potter, this was seeing his parents alive and well. The mirror's name is Erised backwards, meaning \"I see red,\" indicating that it reveals desires, often connected to love and loss.\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Query: How does a Patronus charm work?\n",
      "Answer: A Patronus charm creates a positive, powerful force in the form of an animal to repel Dementors. These creatures feed on human happiness, causing feelings of despair and hopelessness. By conjuring a Patronus, a wizard or witch can shield themselves from a Dementor's influence. The form of the Patronus often reflects the individual's personality or experiences.\n",
      "\n",
      "\n",
      "Example 3:\n",
      "Query: What are the Hogwarts Houses and their characteristics?\n",
      "Answer: Hogwarts School of Witchcraft and Wizardry is divided into four houses: Gryffindor, Hufflepuff, Ravenclaw, and Slytherin. Gryffindor values courage, chivalry, and determination. Hufflepuff emphasizes hard work, loyalty, and fair play. Ravenclaw prizes intelligence, wit, and a love of learning. Slytherin characteristics include ambition, cunning, and resourcefulness.\n",
      "\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "- The green light flashed around the room and she dropped like her husband. The child had not cried all this time: He could stand, clutching the bars of his crib, and he looked up into the intruder’s face with a kind of bright interest, perhaps thinking that it was his father who hid beneath the cloak, making more pretty lights, and his mother would pop up any moment, laughing — He pointed the wand very carefully into the boy’s face: He wanted to see it happen, the destruction of this one, inexplicable danger. The child began to cry: It had seen that he was not James. He did not like it crying, he had never\n",
      "- I heard he’s a sort of savage — lives in a hut on the school grounds and every now and then he gets drunk, tries to do magic, and ends up setting fire to his bed.” “I think he’s brilliant,” said Harry coldly. “Do you?”said the boy, with a slight sneer. “Why is he with you?Where are your parents?” “They’re dead,” said Harry shortly. He didn’t feel much like going into the matter with this boy. “Oh, sorry,” said the other, not sounding sorry at all. “But they were our\n",
      "- M  CHAPTER ONE THE BOY WHO LIVED r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense. Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere. The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn’t think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street.\n",
      "- man at the bar. “War turned him funny, if you ask me,” said the landlord. “Told you I wouldn’t like to get on the wrong side of Frank, didn’t I, Dot?”said an excited woman in the corner. “Horrible temper,” said Dot, nodding fervently. “I remember, when he was a kid . . .”By the following morning, hardly anyone in Little Hangleton doubted that Frank Bryce had killed the Riddles. But over in the neighboring town of Great Hangleton, in the dark and dingy police station, Frank was stubbornly repeating, again and again, that he was innocent, and that the only person he had seen near the house on the day of the Riddles’ deaths had been a teenage boy, a stranger, dark-haired and pale. Nobody else in the village had seen any such boy, and the police were quite sure that Frank had invented him. Then, just when things were looking very serious for Frank, the report on the Riddles’ bodies came back and changed everything.\n",
      "- A tall, black-haired boy was leaning against the nearest pillar, watching. He was strangely blurred around the edges, as though Harry were looking at him through a misted window. But there was no mistaking him — “Tom — Tom Riddle?”Riddle nodded, not taking his eyes off Harry’s face. “What d’you mean, she won’t wake?”Harry said desperately. “She’s not — she’s not — ?” “She’s still alive,” said Riddle. “But only just.”Harry stared at him.\n",
      "- If he could only have died on that summer’s night when he had left number four, Privet Drive, for the last time, when the noble phoenix-feather wand had saved him!If he could only have died like Hedwig, so quickly he would not have known it had happened!Or if he could have launched himself in front of a wand to save someone he loved. . . . He envied even his parents’ deaths now. This cold-blooded walk to his own destruction would require a different kind of bravery. He felt his fingers trembling slightly and made an effort to control them, although no one could see him; the portraits on the walls were all empty. Slowly, very slowly, he sat up, and as he did so he felt more alive and more aware of his own living body than ever before. Why had he never appreciated what a miracle he was, brain and nerve and bounding heart?It would all be gone . . .or at least, he would be gone from it.\n",
      "- been able to stomach the small ones whining in the orphanage — “Avada Kedavra!”And then he broke: He was nothing, nothing but pain and terror, and he must hide himself, not here in the rubble of the ruined house, where the child was trapped and screaming, but far away . . .far away. . . . “No,” he moaned. The snake rustled on the filthy, cluttered floor, and he had killed the boy, and yet he was the boy. . . . “No . . .”And now he stood at the broken window of Bathilda’s house, immersed in memories of his greatest loss, and at his feet the great snake slithered over broken china and glass . . . He looked down and saw something . . .something incredible. . . . “No . . .” “\n",
      "- They rode their bicycles over the lawns Frank worked so hard to keep smooth. Once or twice, they broke into the old house for a dare. They knew that old Frank’s devotion to the house and grounds amounted almost to an obsession, and it amused them to see him limping across the garden, brandishing his stick and yelling croakily at them. Frank, for his part, believed the boys tormented him because they, like their parents and grandparents, thought him a murderer. So when Frank awoke one night in August and saw something very odd up at the old house, he merely assumed that the boys had gone one step further in their attempts to punish him. It was Frank’s bad leg that woke him; it was paining him worse than ever in his old age. He got up and limped downstairs into the kitchen with the idea of refilling his hot-water bottle to ease the stiffness in his knee. Standing at the sink, filling the kettle, he looked up at the Riddle House and saw lights glimmering in its upper windows. Frank knew at once what was going on. The boys had broken into the house again, and judging by the flickering quality of the light, they had started a fire.\n",
      "- “It’s not ours,” said a young man’s voice. “Everything on the other side of the valley belongs to us, but that cottage belongs to an old tramp called Gaunt, and his children. The son’s quite mad, you should hear some of the stories they tell in the village —” The girl laughed. The jingling, clopping noises were growing louder and louder. Morfin made to get out of his armchair. “Keep your seat,” said his father warningly, in Parseltongue. “Tom,” said the girl’s voice again, now so close they were clearly right beside the house, “I might be wrong — but has somebody nailed a snake to that door?” “Good lord, you’re right!”said the man’s voice. “That’ll be the son, I told you he’s not right in the head.\n",
      "- Then a noise reached him through the unformed nothingness that surrounded him: the small soft thumpings of something that flapped, flailed, and struggled. It was a pitiful noise, yet also slightly indecent. He had the uncomfortable feeling that he was eavesdropping on something furtive, shameful. For the first time, he wished he were clothed. Barely had the wish formed in his head than robes appeared a short distance away. He took them and pulled them on: They were soft, clean, and warm. It was extraordinary how they had appeared, just like that, the moment he had wanted them. . . . He stood up, looking around. Was he in some great Room of Requirement?The longer he looked, the more there was to see.\n",
      "\n",
      "Relevant passages: <extract relevant passages from the context here>\n",
      "User query: Explain chapter one : THE BOY WHO LIVED in few words\n",
      "Answer:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get relevant resources\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "    \n",
    "# Create a list of context items\n",
    "context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "# Format prompt with context items\n",
    "prompt = prompt_formatter(query=query,\n",
    "                          context_items=context_items)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Explain chapter one : THE BOY WHO LIVED in few words\n",
      "RAG answer:\n",
      "<bos>The passage describes the emotional state of a young boy named Tom Riddle. He feels a strong desire to see and destroy something, but he is unable to do so due to its fate. He envies his parents' deaths and feels a fear that he will be like them. He also feels a deep sense of loss when he thinks about past glories that he has missed out on.<eos>\n",
      "CPU times: total: 4.38 s\n",
      "Wall time: 5.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate an output of tokens\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             temperature=1, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
    "                             do_sample=True, # whether or not to use sampling, see https://huyenchip.com/2024/01/16/sampling.html for more\n",
    "                             max_new_tokens=256) # how many new tokens to generate from prompt \n",
    "\n",
    "# Turn the output tokens into text\n",
    "output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{output_text.replace(prompt, '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
